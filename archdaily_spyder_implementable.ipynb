{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archdaily爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ——爬取archdaily搜索页下所有项目的大图，以及项目信息                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆分 'https://www.archdaily.com/search/projects/categories/train-station'\n",
    "#url='https://www.archdaily.com'\n",
    "#url_search='/search/projects/categories/train-station'\n",
    "#以下需要设置：\n",
    "\n",
    "url='https://www.archdaily.com'\n",
    "url_search='/search/projects/categories/train-station'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置搜索页数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_pages = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置输出目录路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir='./archdaily'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置好以上之后，点 Cell - Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import socket\n",
    "import urllib\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(text_search_page):\n",
    "    result=re.findall('<a class=\"afd-search-list__link\" href=\"(.*?)\">',text_search_page,re.S)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_links=[]\n",
    "for i in range(num_of_pages):\n",
    "    if i < 30:\n",
    "    continue\n",
    "    url_page=url+url_search + '?page=' + str(i+1)\n",
    "    #print(url_page)\n",
    "    r = requests.get(url_page)\n",
    "    print(r.status_code)\n",
    "#状态码200表示请求成功\n",
    "    text=r.text\n",
    "    project_links+=get_links(text)\n",
    "\n",
    "print(project_links)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(link):\n",
    "    url_project = url + link\n",
    "    r = requests.get(url_project)\n",
    "    ht=r.text\n",
    "    soup = BeautifulSoup(ht , 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从项目页获取gallery页url\n",
    "def get_photos_pageURL(link):\n",
    "    url_project = url + link\n",
    "    r = requests.get(url_project)\n",
    "    text=r.text\n",
    "    #result = re.findall(\"<a class='js-image-size__link.*?' href='(.*?)'.*?style\",text,re.S)\n",
    "    #result = re.findall(\"<a class='js-image-size__link.*?href='(/.*?)'.*?style\",text,re.S)\n",
    "    #result = re.findall(\"<a class='js-image-size__link.*?href='\"+link+\"(.*?).*?style\",text,re.S)\n",
    "    result = re.findall(\"href='\"+link+\"(.*?-jpg|.*?-photo|.*?-image)\",text,re.S)\n",
    "    url_photos = url_project + result[0]\n",
    "    print('photosURL: ' + url_photos)\n",
    "    return url_photos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_links=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "while(i < len(project_links)+1):\n",
    "    link=project_links[i-1]\n",
    "    print(i)\n",
    "    i+=1\n",
    "    try:\n",
    "        url_photos=get_photos_pageURL(link)\n",
    "        photos_links.append(url_photos)\n",
    "    except BaseException:\n",
    "        continue\n",
    "#print(photos_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(photos_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "i=1\n",
    "while(i<len(project_links)+1):\n",
    "    print(i)\n",
    "    link=project_links[i-1]\n",
    "    i+=1\n",
    "    soup=get_soup(link)\n",
    "    \n",
    "    project_name=soup.h1.string.strip().split('/')[0]\n",
    "    print(project_name)\n",
    "    info=['name']\n",
    "    value=[project_name]\n",
    "\n",
    "    h3s=soup.find_all(name='h3',class_='afd-char-title')\n",
    "    h3s=list(set(h3s)\n",
    "            )\n",
    "    for j in range(len(h3s)):\n",
    "        info.append(h3s[j].string.strip())\n",
    "        contents=h3s[j].next_sibling.next_sibling.contents\n",
    "        temp=''\n",
    "        for c in contents:\n",
    "            if(isinstance(c,bs4.element.NavigableString)):\n",
    "                temp += c.strip()\n",
    "            elif(isinstance(c,bs4.element.Tag)):\n",
    "                temp += c.string.strip()\n",
    "        value.append(temp)\n",
    "    \n",
    "    dict1 = dict(zip(info,value))\n",
    "    df=df.append(dict1,ignore_index=True)\n",
    "\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.exists(out_dir)):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(out_dir+'/out.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1 #断点，起始项目序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while(j<len(photos_links)+1):\n",
    "#    if(j==2):\n",
    "#        break\n",
    "    url_photos=photos_links[j-1]\n",
    "    print(url_photos)\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url_photos)\n",
    "    except BaseException:\n",
    "        continue\n",
    "        \n",
    "    #print(r.status_code)\n",
    "    text=r.text\n",
    "    \n",
    "    try:\n",
    "        result=re.findall(\"url_large&quot;:&quot;(.*?)&quot;,&quot;url_slideshow\",text)\n",
    "    except BaseException:\n",
    "        continue\n",
    "    \n",
    "    path = out_dir+'/'+str(j)\n",
    "    if(not os.path.exists(path)):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    i=1 #断点，当前项目起始图片序号\n",
    "    for pic in result:\n",
    "        try:\n",
    "            res=re.search(\"jpg/(.*?)\\.jpg\",pic)    \n",
    "            name=res.group(1)\n",
    "            r = requests.get(pic)\n",
    "            print(str(i)+'.jpg')\n",
    "            with open(path+'/'+str(i)+'.jpg', 'wb')as fp:\n",
    "                fp.write(r.content)\n",
    "        except BaseException:\n",
    "            continue\n",
    "        i+=1\n",
    "    j+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
